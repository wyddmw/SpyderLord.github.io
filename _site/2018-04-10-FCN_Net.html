<h2 id="fcn_net">FCN_Net</h2>
<h3 id="写在前面-2018-03-28">写在前面 2018-03-28</h3>
<p>　　FCN是之前已经看完了的论文了,因为显卡内存不够的问题,虽然有demo的程序,但是始终没有能够运行起来这个程序,本来想着往下继续看下去吧,但是看到MultiNet之后,发现这部分的基础太薄弱了,虽然MultiNet的论文本身并没有特别难理解的,但是在程序u运行部分,我还是被困住了,而且感觉这一困就是快一周了,始终没有找到在论文或是在程序运行上的突破口,程序确实看不懂,有一点我需要承认的是,在之前做车的时候,我就表现出了一种惰性,对于自己理解起来的程序,我总是不愿意静心去好好看看代码的结构,到底是如何实现的,其实我也想跳过去不看,打退堂鼓,然而任务横亘在面前真的是跳不过去啊…长时间陷在找不到突破口的阶段中,感觉时间没有完全用来去解决需要解决的问题,都花在一些不必要的设置上了,所以效率就很低.<br /></p>
<h3 id="分割线2018-04-10">分割线　2018-04-10</h3>
<p>　　论文基本上看完了，代码也跑过一个demo，现在重新回来看这个网络结构，主要是在上采样部分还是有一点内容不太理解，在最优化部分是如何进行optimization的，在dataset上的设计是什么样的。<br /></p>
<h4 id="upsampledeconvbilinear-kernels">upsample|deconv|bilinear kernels</h4>
<p>　　终于差不多搞明白了在FCN中出现的这些名词之间的关系。首先，明确upsample的作用是进行放大，几乎都是采用内插值的方法，在paper中也提到了，使用的方法是双线性内插的方法，和数字图像处理中使用的双线性内插是相同的原理。因为是进行语义分割的任务，我们需要图像在空间上的信息，从卷积层到全连接层的这个过程会丢失掉空间位置的信息，所以我们需要对CNN的输出进行upsample操作，得到和原始输入图像相同大小的输出。在知乎上看到了答案，印证了自己的想法，就是如果FCN上采样部分的操作就是双线性内插法的过程。<br />
　　可以这么说——deconv/upsample差不多可以认为是插值的一种形式。<br />
　　自己理解一下子哈，应该就是通过deconv去实现一下bilinear。在CSDN上的一篇博客中，作者说道，fcn中的源码对卷积核的双线性插值进行初始化，看来确实是在deconv的过程中去执行双线性插值的运算。在FCN paper中说了，通过transpose conv可以实现learnable upsample。在paper中，作者说的是deconv中的kernel是可以学习即改变的，同样也可以是固定的值。如果是固定的kernel我们完全可以直接设定好内插中的参数，这样做的话，整个网络中用到的超参数实际上就是CNN中的conv部分的超参数了～上面这小部分是自己的猜想，没有看代码验证自己想的对不对。<br />
　　猛地感觉FCN有点厉害了，可以使用CNN训练的网络，教会机器识别单一的某个物体，然后给出综合的一张图，机器就能够通过bilinear进行上采样，最终实现semantic segmentation，想一下，其实还是应该是特征信息已经通过CNN提取出来了，然后从featuremap到heatmap，语义分割bingo～太厉害了。
　　写到这里已经是晚上1点了，开始在实验室过夜的生活，坚持一个月，直到项目结题。</p>
