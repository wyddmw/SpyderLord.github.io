<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    * Revised:        Mukosame
    -->
    <meta charset="utf-8" />
    <title>FaceNet学习 | Spyder's blog</title>
    <meta name="author" content="SpyderLord" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Everything about SpyderLord" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/.vscode" />
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">SpyderLord</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="https://github.com/SpyderLord/" target="_blank" style="margin-left:-5px;"><img src="https://github.com/favicon.ico" alt="" width="22"/></a>
           <!-- <a href="http://www.zhihu.com/people/xiang-xiao-yu-20" target="_blank" style="text-align:right"><img src="http://www.zhihu.com/favicon.ico" alt="" width="22"/></a>-->
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/FaceNet%E5%AD%A6%E4%B9%A0" title="FaceNet学习">FaceNet学习</a></h1>
        <p class="entry-date">2018-06-04</p>
        <h2 id="写在前面">写在前面</h2>
<p>　　首先是为什么要学习这个FaceNet。和研究生一起参加一个智慧城市的比赛，赛题就是带遮挡的人脸识别。和之前做的中科院的项目也算是有点联系，都是机器视觉方面的内容。在我看这个赛题还是比较有意思的，也是比较符合当前生活的场景的，每一个人的图片只有很少的几张，但是会有非常多的人需要进行识别。按照之前的思路，对应的会有非常多的种类，但是每个种类对应的图片的数量非常少，如果想让机器准确每一个人的特征，然后进行识别，这显然是有点不现实的，因为每个人的图像太少了，训练出来的模型很有可能是欠拟合的。其实在现实生活中，如果我们想要做一个识别的系统的话，我们也不可能去采集非常多的图像。如果需要对一个新的人进行识别呢？重新训练去训练一下这个网络？FaceNet的提出应该说是非常好的解决了这个问题吧。</p>

<h2 id="introduction">Introduction</h2>
<p>　　在paper的Introduction部分，作者介绍到，他们的方法是建立在学习一个欧式距离的embedding——这个embedding应该说是非常重要的，具体应该翻译成什么，我想不出来合适的对应。The network is trained such that the squared L2 distances in the embedding space directly correspond to face similarity:face of the same person have small distances and face of different people have large distances.Once this embedding has been produced,then the aforementioned tasks become straight-forward:face verification simply involves thresholding the distance between the two embeddings;recognition becomes a K-NN classificaiton problem.<br />
　　Previous face recognition approaches baesd on deep networks use a classification layer trained over a set of known face identities and then take an intermediate bottleneck layer as representation used to generalize recognition beyond the set of identities used in training.The downsides of this approach are its indirectness and its inefficiency;one has to hope that the bottleneck representation generalizes well to new faces;and by using a bottleneck layer the representation size per face is usually very large.<br />
　　In contrast to these approaches,FaceNet directly trains its output to be a compact 128-D embedding using a triplet-based loss function based on LMNN.Our triplets consist of two matching face thumbnails and a non-matching face thumbnail and the loss aims to separate the positive pair from the negative by a distance margin.<br />
　　Our method uses a deep convolutional network trained to directly optimize the embedding itself,rather than an intermediate bottleneck layer as in previous deep learning approaches.<br />
<img src="/downloads/facenetArchitecture.png" alt="" />
<img src="/downloads/facenet.png" alt="" />
　　optimize的作用就是使相同Id对应的照片欧式距离最小化，不同Id的照片对应的欧式距离最大化。<br />
　　对于embedding的这个概念——We strive for an embedding f(x),from an image x into a feature space R,such that the squared distance between all faces,independent of imaging conditions,of the same identity is small,whereas the squared distance between a pair of face images from different identities is large.经过embedding之后，将图像转换成一个空间上的特征——f(x)，然后使用triplet三元损失函数进行优化。</p>

<h3 id="triplet-loss">Triplet Loss</h3>
<p>　　这个损失是在这个网络中提出来的，就理解为三元损失函数吧。在吴恩达的课程中，对这个三元损失函数的介绍是如下的：要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降进行优化。<br />
　　使用三元组损失函数需要我们对数据集有特殊的要求，我们需要把数据集分成如下三个部分：Anchor图片，Positive图片，和Negative图片。我们需要同时看这三张照片，首先是看Anchor图片，我们希望Anchor图片和Positive图片的距离很近，Negative和Anchor不是同一个人，我们会希望对应的距离远一些，我们将对应的图片简写成APN，如果我们想把这些写成公式的话，我们希望网络的参数或者编码能够满足下面的特性：||f(A)-f(P)||^2这个数值是非常小的，其中f(A)表示提取的Anchor图片的特征。我们希望它小于等于f(A)和f(N)之间的距离，或是说它们范数的平方。(即||f(A)-f(P)||^2&lt;=||f(A)-f(N)||^2)，然后我们可以对这个这个式子再进行一下修改，添加一个间隔参数，有点类似于SVM损失函数。就是我们希望f(A)、f(P)之间的距离和f(A)、f(N)之间的距离差至少要比这个间隔参数要大。<br />
　　Loss(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+a,0)，其实和SVM的损失函数非常像了，就是只要能够满足这个距离的间隔就认为是理想的了。<br />
　　对Triplet Loss函数补充一些paper中的内容：The embedding is represented by f(x).It embeds an image x into a d-dimensional Euclidean space.Additionally,we constrain this embedding to live on the d-dimensional hypersphere——映射一个超球面上，所以这个应该就是L2Norm的作用所在？Deeplearning Architecture之后接的是一个L2 Norm，所以就是映射到了N维度的超球面上。
<img src="/downloads/triplet1.png" alt="" />
<img src="/downloads/triplet2.png" alt="" /></p>

<h3 id="l2范数的一点补充">L2范数的一点补充</h3>
<p><img src="/downloads/L2Norm.png" alt="" /></p>

<h2 id="inception-network">Inception Network</h2>
<p>　　Inception Network这种网络结构，是一种googlenet，使用的是一种net-in-net的网路，作者在paper中说明的是，使用这种层套层的网络结构，目的是为了增强网络的表达能力。实际上就是之前看到的GoogleNet的网络结构。
<img src="/downloads/inception1.png" alt="" />
<img src="/downloads/inception2.png" alt="" /></p>

    </div>

    <div class="sidenav">
        <h2>Blog</h2>
        <ul class="artical-list">
        
            <li><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">大数据和机器学习学习笔记</a></li>
        
            <li><a href="/%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E7%AB%AF%E5%8D%88%E5%87%BA%E8%A1%8C">一个人的端午出游</a></li>
        
            <li><a href="/%E8%BF%98%E6%98%AF%E5%8C%97%E4%BA%AC">还是北京</a></li>
        
            <li><a href="/FaceNet%E5%AD%A6%E4%B9%A0">FaceNet学习</a></li>
        
            <li><a href="/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83">分类和回归之间的比较</a></li>
        
            <li><a href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0">神经网络的复习</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0">DeepLearning复习</a></li>
        
            <li><a href="/BinarySearchTree">Binary Search Tree</a></li>
        
            <li><a href="/%E5%B0%86%E6%9D%A5%E7%9A%84%E4%BD%A0%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%84%9F%E8%B0%A2%E7%8E%B0%E5%9C%A8%E5%8A%AA%E5%8A%9B%E7%9A%84%E8%87%AA%E5%B7%B1">将来的你一定会感谢现在努力的自己</a></li>
        
            <li><a href="/PSPNet%E7%9A%84%E5%AD%A6%E4%B9%A0">PSP网络的学习</a></li>
        
            <li><a href="/ResNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0">ResNet网络的学习</a></li>
        
            <li><a href="/MultiNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A1%A5%E5%85%85">MultiNet网络学习的补充</a></li>
        
            <li><a href="/Optimization">Optimization</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E6%89%A7%E8%A1%8C%E5%8A%9B">关于执行力</a></li>
        
            <li><a href="/FCN_Net%E7%BB%93%E6%9E%84%E7%9A%84%E4%B8%80%E7%82%B9%E8%A1%A5%E5%85%85">FCN_Net的补充</a></li>
        
            <li><a href="/FCN">FCN_Net</a></li>
        
            <li><a href="/%E6%B8%85%E6%98%8E%E5%9C%A8%E5%8C%97%E4%BA%AC">清明在北京</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%86%99%E8%87%AA%E8%8D%90%E4%BF%A1">关于写保研自荐信</a></li>
        
            <li><a href="/overfit">Overfitting</a></li>
        
            <li><a href="/ordinary-vs-cnn">普通神经网络和卷积神经网络之间比较</a></li>
        
            <li><a href="/multinet">MultiNet学习</a></li>
        
            <li><a href="/first">第一篇博文</a></li>
        
            <li><a href="/end-to-end">end-to-end</a></li>
        
            <li><a href="/WhyDeeplearning">WhyDeepLearning</a></li>
        
            <li><a href="/DataProblem">MiniDataSet</a></li>
        
        </ul>

        <h2>Dump</h2>
        <ul class="artical-list">
        
            <li><a href="/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8A%A0%E8%BD%BD">加载预训练好的模型时遇到的问题</a></li>
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E9%83%A8%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0">Python从外部传入参数</a></li>
        
            <li><a href="/%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B">如何保存一个训练好的模型或是参数</a></li>
        
            <li><a href="/CV%E6%8C%91%E6%88%98%E8%B5%9B">CV中非常重要的挑战赛</a></li>
        
            <li><a href="/%E5%9B%BE%E8%AE%BA%E7%AE%97%E6%B3%95">图论算法</a></li>
        
            <li><a href="/%E8%BF%91%E4%B8%A4%E5%A4%A9%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E6%84%9F%E6%83%B3">近两天对深度学习的一点感想</a></li>
        
            <li><a href="/benchmark">几个概念的理解</a></li>
        
            <li><a href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%86">深度学习语义分割中的度量标准</a></li>
        
            <li><a href="/logits">Logits</a></li>
        
            <li><a href="/iteration%E5%92%8Cepoch">iteration和epoch比较</a></li>
        
            <li><a href="/Batch_Normalization">Batch_Normalization</a></li>
        
            <li><a href="/Memory_arrangement">linux动态内存管理</a></li>
        
            <li><a href="/ground_truth">ground truth</a></li>
        
            <li><a href="/VGG16">CNN_Architecture</a></li>
        
        </ul>

        <h2>Project</h2>
        <ul class="artical-list">
        
            <li><a href="/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1">课程设计</a></li>
        
            <li><a href="/%E6%89%8B%E5%86%99%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C">手写深度网络</a></li>
        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>


    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
