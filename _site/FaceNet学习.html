<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    * Revised:        Mukosame
    -->
    <meta charset="utf-8" />
    <title>FaceNet学习 | Spyder's blog</title>
    <meta name="author" content="SpyderLord" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Everything about SpyderLord" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/.vscode" />
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">SpyderLord</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="https://github.com/SpyderLord/" target="_blank" style="margin-left:-5px;"><img src="https://github.com/favicon.ico" alt="" width="22"/></a>
           <!-- <a href="http://www.zhihu.com/people/xiang-xiao-yu-20" target="_blank" style="text-align:right"><img src="http://www.zhihu.com/favicon.ico" alt="" width="22"/></a>-->
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/FaceNet%E5%AD%A6%E4%B9%A0" title="FaceNet学习">FaceNet学习</a></h1>
        <p class="entry-date">2018-06-04</p>
        <h2 id="写在前面">写在前面</h2>
<p>　　首先是为什么要学习这个FaceNet。和研究生一起参加一个智慧城市的比赛，赛题就是带遮挡的人脸识别。和之前做的中科院的项目也算是有点联系，都是机器视觉方面的内容。在我看这个赛题还是比较有意思的，也是比较符合当前生活的场景的，每一个人的图片只有很少的几张，但是会有非常多的人需要进行识别。按照之前的思路，对应的会有非常多的种类，但是每个种类对应的图片的数量非常少，如果想让机器准确每一个人的特征，然后进行识别，这显然是有点不现实的，因为每个人的图像太少了，训练出来的模型很有可能是欠拟合的。其实在现实生活中，如果我们想要做一个识别的系统的话，我们也不可能去采集非常多的图像。如果需要对一个新的人进行识别呢？重新训练去训练一下这个网络？FaceNet的提出应该说是非常好的解决了这个问题吧。</p>

<h2 id="introduction">Introduction</h2>
<p>　　在paper的Introduction部分，作者介绍到，他们的方法是建立在学习一个欧式距离的embedding——这个embedding应该说是非常重要的，具体应该翻译成什么，我想不出来合适的对应。The network is trained such that the squared L2 distances in the embedding space directly correspond to face similarity:face of the same person have small distances and face of different people have large distances.Once this embedding has been produced,then the aforementioned tasks become straight-forward:face verification simply involves thresholding the distance between the two embeddings;recognition becomes a K-NN classificaiton problem.<br />
　　Previous face recognition approaches baesd on deep networks use a classification layer trained over a set of known face identities and then take an intermediate bottleneck layer as representation used to generalize recognition beyond the set of identities used in training.The downsides of this approach are its indirectness and its inefficiency;one has to hope that the bottleneck representation generalizes well to new faces;and by using a bottleneck layer the representation size per face is usually very large.<br />
　　In contrast to these approaches,FaceNet directly trains its output to be a compact 128-D embedding using a triplet-based loss function based on LMNN.Our triplets consist of two matching face thumbnails and a non-matching face thumbnail and the loss aims to separate the positive pair from the negative by a distance margin.<br />
　　Our method uses a deep convolutional network trained to directly optimize the embedding itself,rather than an intermediate bottleneck layer as in previous deep learning approaches.<br />
<img src="/downloads/facenetArchitecture.png" alt="" />
<img src="/downloads/facenet.png" alt="" />
　　optimize的作用就是使相同Id对应的照片欧式距离最小化，不同Id的照片对应的欧式距离最大化。<br />
　　对于embedding的这个概念——We strive for an embedding f(x),from an image x into a feature space R,such that the squared distance between all faces,independent of imaging conditions,of the same identity is small,whereas the squared distance between a pair of face images from different identities is large.经过embedding之后，将图像转换成一个空间上的特征——f(x)，然后使用triplet三元损失函数进行优化。</p>

<h3 id="triplet-loss">Triplet Loss</h3>
<p>　　这个损失是在这个网络中提出来的，就理解为三元损失函数吧。在吴恩达的课程中，对这个三元损失函数的介绍是如下的：要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降进行优化。<br />
　　使用三元组损失函数需要我们对数据集有特殊的要求，我们需要把数据集分成如下三个部分：Anchor图片，Positive图片，和Negative图片。我们需要同时看这三张照片，首先是看Anchor图片，我们希望Anchor图片和Positive图片的距离很近，Negative和Anchor不是同一个人，我们会希望对应的距离远一些，我们将对应的图片简写成APN，如果我们想把这些写成公式的话，我们希望网络的参数或者编码能够满足下面的特性：||f(A)-f(P)||^2这个数值是非常小的，其中f(A)表示提取的Anchor图片的特征。我们希望它小于等于f(A)和f(N)之间的距离，或是说它们范数的平方。(即||f(A)-f(P)||^2&lt;=||f(A)-f(N)||^2)，然后我们可以对这个这个式子再进行一下修改，添加一个间隔参数，有点类似于SVM损失函数。就是我们希望f(A)、f(P)之间的距离和f(A)、f(N)之间的距离差至少要比这个间隔参数要大。<br />
　　Loss(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+a,0)，其实和SVM的损失函数非常像了，就是只要能够满足这个距离的间隔就认为是理想的了。<br />
　　对Triplet Loss函数补充一些paper中的内容：The embedding is represented by f(x).It embeds an image x into a d-dimensional Euclidean space.Additionally,we constrain this embedding to live on the d-dimensional hypersphere——映射一个超球面上，所以这个应该就是L2Norm的作用所在？Deeplearning Architecture之后接的是一个L2 Norm，所以就是映射到了N维度的超球面上。
<img src="/downloads/triplet1.png" alt="" />
<img src="/downloads/triplet2.png" alt="" /></p>

<h3 id="l2范数的一点补充">L2范数的一点补充</h3>
<p><img src="/downloads/L2Norm.png" alt="" /></p>

<h2 id="inception-network">Inception Network</h2>
<p>　　Inception Network这种网络结构，是一种googlenet，使用的是一种net-in-net的网路，作者在paper中说明的是，使用这种层套层的网络结构，目的是为了增强网络的表达能力。实际上就是之前看到的GoogleNet的网络结构。
<img src="/downloads/inception1.png" alt="" />
<img src="/downloads/inception2.png" alt="" /></p>

<h2 id="分割线-2018-06-30">分割线 2018-06-30</h2>
<p>　　和研究生的比赛已经完成了一部分，整个网络的模型已经想出来应该怎么建了，现在需要做的就是如何去训练这个网络模型了。在实际的训练中，我们在gallory和probe测试中，模型预测出来的精度并不高，出现这样的原因我们现在想的是因为整个数据集的划分有点不合理，换句话说，我们最后一层接的是支持向量机，认为同一个人对应的分类应该是1，不同的人对应的分类是0，但是在高维空间中，更多的点对应的是0这个分类，而1这个分类的点数非常少，所以在构造超平面的时候就会造成这个超平面是不准确的，进而使分类的精度非常低，对于这个问题我们已经有了解决的思路，具体的效果还要看进一步的训练效果。<br />
　　在这里想补充的一点的是关于FaceNet的网络，它和siamese网络具体是什么样的一个关系没有去仔细研究。siamese网络提出的一个思路是使用相同的网络包括参数什么的都是相同的，经过计算之后可以得到两个具有相同意义的两个结果，或是说两个相互独立的特征，对特征进行比较，可以知道这两个人是否是相同的一个人。在FaceNet中，应该说也是使用了这样的一种思路，使用Inception的网络结构进行特征提取，然后得到一个128维度的embedding，得到embedding之后，使用Triplet损失函数对整个网络进行优化，目的是为了使embedding提取出来的特征，如果是相同的人，这个特征的欧氏距离（对应L2范数）最小，如果是不同的人对应的距离最大。所以实际上，整个FaceNet最后是没有svm或是softmax分类器的，输出的只是一个embedding特征值，最后优化的也是这个embedding。</p>

    </div>

    <div class="sidenav">
        <h2>Blog</h2>
        <ul class="artical-list">
        
            <li><a href="/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%9A%84%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1">研究生的数学建模</a></li>
        
            <li><a href="/%E4%B8%8A%E6%B5%B7%E5%9B%9E%E9%A1%BE">暑假在迪士尼</a></li>
        
            <li><a href="/Faster_RCNN">Faster RCNN</a></li>
        
            <li><a href="/Fast-RCNN">Fast R-CNN</a></li>
        
            <li><a href="/R-CNN">R-CNN学习笔记</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0%E4%BA%94">DeepLearning复习(五)</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0%E5%9B%9B">DeepLearning(四)</a></li>
        
            <li><a href="/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%A4%8D%E4%B9%A0">Deeplearning复习(三)</a></li>
        
            <li><a href="/%E4%B8%80%E6%AE%B5%E5%A5%94%E6%B3%A2%E4%B9%8B%E5%90%8E">一段奔波结束</a></li>
        
            <li><a href="/%E9%99%88%E8%80%81%E5%B8%88%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93">陈老师的论文简述</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0-%E4%BA%8C">DeepLearning复习(二)</a></li>
        
            <li><a href="/%E5%8F%88%E6%98%AF%E4%B8%80%E7%AF%87%E5%85%B3%E4%BA%8E%E4%BF%9D%E7%A0%94%E7%9A%84%E9%9A%8F%E6%84%9F">又是保送过程中的一点随感</a></li>
        
            <li><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">大数据和机器学习学习笔记</a></li>
        
            <li><a href="/%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E7%AB%AF%E5%8D%88%E5%87%BA%E8%A1%8C">一个人的端午出游</a></li>
        
            <li><a href="/%E8%BF%98%E6%98%AF%E5%8C%97%E4%BA%AC">还是北京</a></li>
        
            <li><a href="/FaceNet%E5%AD%A6%E4%B9%A0">FaceNet学习</a></li>
        
            <li><a href="/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83">分类和回归之间的比较</a></li>
        
            <li><a href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0">神经网络的复习</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0-%E4%B8%80">DeepLearning复习（一）</a></li>
        
            <li><a href="/BinarySearchTree">Binary Search Tree</a></li>
        
            <li><a href="/%E5%B0%86%E6%9D%A5%E7%9A%84%E4%BD%A0%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%84%9F%E8%B0%A2%E7%8E%B0%E5%9C%A8%E5%8A%AA%E5%8A%9B%E7%9A%84%E8%87%AA%E5%B7%B1">将来的你一定会感谢现在努力的自己</a></li>
        
            <li><a href="/PSPNet%E7%9A%84%E5%AD%A6%E4%B9%A0">PSP网络的学习</a></li>
        
            <li><a href="/ResNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0">ResNet网络的学习</a></li>
        
            <li><a href="/MultiNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A1%A5%E5%85%85">MultiNet网络学习的补充</a></li>
        
            <li><a href="/Optimization">Optimization</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E6%89%A7%E8%A1%8C%E5%8A%9B">关于执行力</a></li>
        
            <li><a href="/FCN_Net%E7%BB%93%E6%9E%84%E7%9A%84%E4%B8%80%E7%82%B9%E8%A1%A5%E5%85%85">FCN_Net的补充</a></li>
        
            <li><a href="/FCN">FCN_Net</a></li>
        
            <li><a href="/%E6%B8%85%E6%98%8E%E5%9C%A8%E5%8C%97%E4%BA%AC">清明在北京</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%86%99%E8%87%AA%E8%8D%90%E4%BF%A1">关于写保研自荐信</a></li>
        
            <li><a href="/overfit">Overfitting</a></li>
        
            <li><a href="/ordinary-vs-cnn">普通神经网络和卷积神经网络之间比较</a></li>
        
            <li><a href="/multinet">MultiNet学习</a></li>
        
            <li><a href="/first">第一篇博文</a></li>
        
            <li><a href="/end-to-end">end-to-end</a></li>
        
            <li><a href="/WhyDeeplearning">WhyDeepLearning</a></li>
        
            <li><a href="/DataProblem">MiniDataSet</a></li>
        
        </ul>

        <h2>Dump</h2>
        <ul class="artical-list">
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E7%95%8C%E8%AF%BB%E5%8F%96%E5%8F%82%E6%95%B0">python解析命令行参数</a></li>
        
            <li><a href="/anaconda%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85">anaconda安装第三方包</a></li>
        
            <li><a href="/%E5%8D%B7%E7%A7%AF%E5%92%8C%E6%BB%A4%E6%B3%A2%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB">卷积和滤波之间的区别</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E9%97%AE%E9%A2%98">参数初始化的问题</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%92%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%97%AE%E9%A2%98">参数和超参数的问题</a></li>
        
            <li><a href="/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94">杂记随笔</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E8%B4%AB%E5%AF%8C%E5%B7%AE%E8%B7%9D">关于贫富差距的感想</a></li>
        
            <li><a href="/%E4%BE%9D%E7%84%B6%E5%9B%9E%E5%BD%92%E5%92%8C%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%B7%AE%E5%88%AB%E7%9A%84%E9%97%AE%E9%A2%98">依然是SVM和线性回归之间的对比问题</a></li>
        
            <li><a href="/%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E4%BD%9C%E7%94%A8">训练集验证集和测试集的作用</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%89">C语言复习三</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%AF%BC%E5%85%A5%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98">关于导入头文件的问题</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%BA%8C">C语言复习二</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%80">C语言复习一</a></li>
        
            <li><a href="/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8A%A0%E8%BD%BD">加载预训练好的模型时遇到的问题</a></li>
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E9%83%A8%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0">Python从外部传入参数</a></li>
        
            <li><a href="/%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B">如何保存一个训练好的模型或是参数</a></li>
        
            <li><a href="/CV%E6%8C%91%E6%88%98%E8%B5%9B">CV中非常重要的挑战赛</a></li>
        
            <li><a href="/%E5%9B%BE%E8%AE%BA%E7%AE%97%E6%B3%95">图论算法</a></li>
        
            <li><a href="/%E8%BF%91%E4%B8%A4%E5%A4%A9%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E6%84%9F%E6%83%B3">近两天对深度学习的一点感想</a></li>
        
            <li><a href="/benchmark">几个概念的理解</a></li>
        
            <li><a href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%86">深度学习语义分割中的度量标准</a></li>
        
            <li><a href="/logits">Logits</a></li>
        
            <li><a href="/iteration%E5%92%8Cepoch">iteration和epoch比较</a></li>
        
            <li><a href="/Batch_Normalization">Batch_Normalization</a></li>
        
            <li><a href="/Memory_arrangement">linux动态内存管理</a></li>
        
            <li><a href="/ground_truth">ground truth</a></li>
        
            <li><a href="/VGG16">CNN_Architecture</a></li>
        
        </ul>

        <h2>Project</h2>
        <ul class="artical-list">
        
            <li><a href="/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93">通信原理复习总结</a></li>
        
            <li><a href="/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1">课程设计</a></li>
        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>


    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
