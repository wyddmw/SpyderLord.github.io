<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    * Revised:        Mukosame
    -->
    <meta charset="utf-8" />
    <title>Fast R-CNN | Spyder's blog</title>
    <meta name="author" content="SpyderLord" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Everything about SpyderLord" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/.vscode" />
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">SpyderLord</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="https://github.com/SpyderLord/" target="_blank" style="margin-left:-5px;"><img src="https://github.com/favicon.ico" alt="" width="22"/></a>
           <!-- <a href="http://www.zhihu.com/people/xiang-xiao-yu-20" target="_blank" style="text-align:right"><img src="http://www.zhihu.com/favicon.ico" alt="" width="22"/></a>-->
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/Fast-RCNN" title="Fast R-CNN">Fast R-CNN</a></h1>
        <p class="entry-date">2018-08-25</p>
        <h2 id="comparision-with-r-cnn-and-sppnet">Comparision with R-CNN and SPPnet</h2>
<p>　　The Region-based Convolutional Network method achieves excellent object detection accuracy by using a deep ConvNet to classify object proposals.There are several drawbacks with R-CNN:Training is complicated.When it comes to R-CNN,first of all,we have to fine-tune a ConvNet on object proposals using a log loss.Then we apply specific linear SVMs to abstract features,which act as object detectors,replacing the softmax classifier learnt by fine-tuning.In the third training stage,the bounding-box regressors are learned.What’s more,training is quite expensive in space and time.The reason why R-CNN is slow is that it performs a ConvNet forward pass for each object proposal without sharing computation.<br />
　　作者首先是以RCNN和SPPnet两种模型为例子进行分析，指出，上述的两种方式存在主要三个弊端：</p>
<ul>
  <li>Training is a multi-stage pipeline:训练需要分成多个步骤来完成。因为自己动手敲了RCNN的网络模型，也自己训练过了一遍，确实发现了这个问题。首先我们需要大数据集来训练我们的卷及网络，然后我们小数据集对网络进行微调优化。而且在自己动手实践的过程中，发现RCNN的占用的数据空间是非常大的。输入一张图片之后，首先我们通过selective search进行region的选择，然后根据IoU的值来打上对应的标签，将数据重新保存在.npy文件中，在进行读取，是非常复杂繁琐的一个过程。在RCNN的训练过程中，第一步进行的是根据物体区域候选框去fine-tune卷积网络，这个时候使用的损失函数是softmax。第二步进行的是根据ConvNet提取出来的特征去训练一个SVM分类器。最后一步是训练一个Bounding-Box回归的学习。</li>
  <li>存在的第二个问题是：训练在时间上和内存空间上的消耗是非常庞大的。</li>
  <li>物体检测的过程是非常慢的：RCNN之所以非常缓慢是因为它对每一个候选区都使用卷积神经网络进行特征的提取，并没有使用计算共享的思路。<br /></li>
</ul>

<p>　　Fast-RCNN模型的优点：</p>
<ul>
  <li>和RCNN、SPPNet相比更高的检测精度Higher detection quality(mAP).</li>
  <li>Training is single-stage,using a muliti-task loss.训练优化并不像之前分成了多个步骤完成，而是一个步骤就完成了。提出了multi-task loss新的评估损失函数。</li>
  <li>Training can update all network layers.能够更新全部的神经网络层。</li>
  <li>对于特征的存储并不需要很大的内存空间。</li>
</ul>

<h2 id="architecture-and-training">Architecture and training</h2>
<p>　　首先放上Fast-RCNN的网络结构：
<img src="/downloads/Fast-RCNN.png" alt="" height="290" width="420" /></p>
<ul>
  <li>selective search在一张图片中得到大约2000个object proposals(这里称为RoI)</li>
  <li>将整个图片放入一个CNN网络中得到一个总的conv feature map。每一个RoI通过ROI Pooling层可以在feature map中找到对应的固定长度的特征向量。</li>
  <li>经过两个全连接层之后转变成一个RoI特征向量。该特征向量可以得到两个输出，两个输出分别是softmax分类器得到的分类结果，另一个是bounding box回归的结果。<br />
　　关于这个bounding box回归值，有一点需要额外补充的地方，也是当时在看</li>
</ul>

<h3 id="the-roi-pooling-layer">The RoI pooling layer</h3>
<p>　　The RoI pooling layer uses max pooling to convert the features inside any valid region of insterest into a small feature map with a fixed spatial extent of H<em>W where H and W are layer hyper-parameters that independent of any particular RoI.<br />
　　RoI max pooling works by dividing the h</em>w RoI window into an H<em>W grid of sub-windows of approximate size h/H</em>w/W and then max-pooling the values in each sub-window into the corresponding output grid cell.<br />
　　在之前的RCNN网络中，需要将所有的region proposals都输入到CNN中，有很多计算是重复进行的。RoI pooling层的提出可以说是Fast RCNN的关键所在了。ROI pooling池化层的作用是使经过Selective search得到的region能够在整幅图像对应的feature map中对应找到自己的patch——feature vector。只需要一步就能在feature map中提取ROI对应的patch。大大提高了网络的计算效率。<br />
　　从目前的理解来看，RoI池化层和第一层的全连接层是相关联的。我们需要满足的是在全连接层的第一层输入的feature vector的size是fixed的。</p>
<h3 id="pre-trained">Pre-trained</h3>
<p>　　As the paper points out, when a pre-trained network initializes a Fast RCNN network, it undergoes three transformations.<br />
　　The last max pooling layer is replaced by a RoI pooling layer that is configured by setting H and W to be compatible with the net’s first fully connected layer.<br />
　　Second, the network’s last fully connected layer and softmax are replaced with two sibling layers described above(a fully connected layer and softmax over K+1 categories and category-specific bounding-box regressors).<br />
　　Third，the network is modified to take two data inputs: a list of images and a list of RoIs in those images. <br />
　　我们在使用大数据集与训练好了之后还需要进行进一步的微调，在训练好的网络结构上需要有三步进行调整。首先是最后一层的max pooling池化层需要改成RoI Pooling池化层，然后是最后一个全连接层和softmax被两个输出层替代，这两个层的输出一个是分类的概率p，另一个是BBX回归。网络的输入是两部分，一个是图像的输入，另一个是RoI列表。<br />
　　</p>

    </div>

    <div class="sidenav">
        <h2>Blog</h2>
        <ul class="artical-list">
        
            <li><a href="/%E4%B8%8A%E6%B5%B7%E5%9B%9E%E9%A1%BE">暑假在迪士尼</a></li>
        
            <li><a href="/Faster_RCNN">Faster RCNN</a></li>
        
            <li><a href="/Fast-RCNN">Fast R-CNN</a></li>
        
            <li><a href="/R-CNN">R-CNN学习笔记</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0%E4%BA%94">DeepLearning复习(五)</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0%E5%9B%9B">DeepLearning(四)</a></li>
        
            <li><a href="/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%A4%8D%E4%B9%A0">Deeplearning复习(三)</a></li>
        
            <li><a href="/%E4%B8%80%E6%AE%B5%E5%A5%94%E6%B3%A2%E4%B9%8B%E5%90%8E">一段奔波结束</a></li>
        
            <li><a href="/%E9%99%88%E8%80%81%E5%B8%88%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93">陈老师的论文简述</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0-%E4%BA%8C">DeepLearning复习(二)</a></li>
        
            <li><a href="/%E5%8F%88%E6%98%AF%E4%B8%80%E7%AF%87%E5%85%B3%E4%BA%8E%E4%BF%9D%E7%A0%94%E7%9A%84%E9%9A%8F%E6%84%9F">又是保送过程中的一点随感</a></li>
        
            <li><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">大数据和机器学习学习笔记</a></li>
        
            <li><a href="/%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E7%AB%AF%E5%8D%88%E5%87%BA%E8%A1%8C">一个人的端午出游</a></li>
        
            <li><a href="/%E8%BF%98%E6%98%AF%E5%8C%97%E4%BA%AC">还是北京</a></li>
        
            <li><a href="/FaceNet%E5%AD%A6%E4%B9%A0">FaceNet学习</a></li>
        
            <li><a href="/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83">分类和回归之间的比较</a></li>
        
            <li><a href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0">神经网络的复习</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0-%E4%B8%80">DeepLearning复习（一）</a></li>
        
            <li><a href="/BinarySearchTree">Binary Search Tree</a></li>
        
            <li><a href="/%E5%B0%86%E6%9D%A5%E7%9A%84%E4%BD%A0%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%84%9F%E8%B0%A2%E7%8E%B0%E5%9C%A8%E5%8A%AA%E5%8A%9B%E7%9A%84%E8%87%AA%E5%B7%B1">将来的你一定会感谢现在努力的自己</a></li>
        
            <li><a href="/PSPNet%E7%9A%84%E5%AD%A6%E4%B9%A0">PSP网络的学习</a></li>
        
            <li><a href="/ResNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0">ResNet网络的学习</a></li>
        
            <li><a href="/MultiNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A1%A5%E5%85%85">MultiNet网络学习的补充</a></li>
        
            <li><a href="/Optimization">Optimization</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E6%89%A7%E8%A1%8C%E5%8A%9B">关于执行力</a></li>
        
            <li><a href="/FCN_Net%E7%BB%93%E6%9E%84%E7%9A%84%E4%B8%80%E7%82%B9%E8%A1%A5%E5%85%85">FCN_Net的补充</a></li>
        
            <li><a href="/FCN">FCN_Net</a></li>
        
            <li><a href="/%E6%B8%85%E6%98%8E%E5%9C%A8%E5%8C%97%E4%BA%AC">清明在北京</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%86%99%E8%87%AA%E8%8D%90%E4%BF%A1">关于写保研自荐信</a></li>
        
            <li><a href="/overfit">Overfitting</a></li>
        
            <li><a href="/ordinary-vs-cnn">普通神经网络和卷积神经网络之间比较</a></li>
        
            <li><a href="/multinet">MultiNet学习</a></li>
        
            <li><a href="/first">第一篇博文</a></li>
        
            <li><a href="/end-to-end">end-to-end</a></li>
        
            <li><a href="/WhyDeeplearning">WhyDeepLearning</a></li>
        
            <li><a href="/DataProblem">MiniDataSet</a></li>
        
        </ul>

        <h2>Dump</h2>
        <ul class="artical-list">
        
            <li><a href="/anaconda%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85">anaconda安装第三方包</a></li>
        
            <li><a href="/%E5%8D%B7%E7%A7%AF%E5%92%8C%E6%BB%A4%E6%B3%A2%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB">卷积和滤波之间的区别</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E9%97%AE%E9%A2%98">参数初始化的问题</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%92%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%97%AE%E9%A2%98">参数和超参数的问题</a></li>
        
            <li><a href="/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94">杂记随笔</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E8%B4%AB%E5%AF%8C%E5%B7%AE%E8%B7%9D">关于贫富差距的感想</a></li>
        
            <li><a href="/%E4%BE%9D%E7%84%B6%E5%9B%9E%E5%BD%92%E5%92%8C%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%B7%AE%E5%88%AB%E7%9A%84%E9%97%AE%E9%A2%98">依然是SVM和线性回归之间的对比问题</a></li>
        
            <li><a href="/%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E4%BD%9C%E7%94%A8">训练集验证集和测试集的作用</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%89">C语言复习三</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%AF%BC%E5%85%A5%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98">关于导入头文件的问题</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%BA%8C">C语言复习二</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%80">C语言复习一</a></li>
        
            <li><a href="/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8A%A0%E8%BD%BD">加载预训练好的模型时遇到的问题</a></li>
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E9%83%A8%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0">Python从外部传入参数</a></li>
        
            <li><a href="/%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B">如何保存一个训练好的模型或是参数</a></li>
        
            <li><a href="/CV%E6%8C%91%E6%88%98%E8%B5%9B">CV中非常重要的挑战赛</a></li>
        
            <li><a href="/%E5%9B%BE%E8%AE%BA%E7%AE%97%E6%B3%95">图论算法</a></li>
        
            <li><a href="/%E8%BF%91%E4%B8%A4%E5%A4%A9%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E6%84%9F%E6%83%B3">近两天对深度学习的一点感想</a></li>
        
            <li><a href="/benchmark">几个概念的理解</a></li>
        
            <li><a href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%86">深度学习语义分割中的度量标准</a></li>
        
            <li><a href="/logits">Logits</a></li>
        
            <li><a href="/iteration%E5%92%8Cepoch">iteration和epoch比较</a></li>
        
            <li><a href="/Batch_Normalization">Batch_Normalization</a></li>
        
            <li><a href="/Memory_arrangement">linux动态内存管理</a></li>
        
            <li><a href="/ground_truth">ground truth</a></li>
        
            <li><a href="/VGG16">CNN_Architecture</a></li>
        
        </ul>

        <h2>Project</h2>
        <ul class="artical-list">
        
            <li><a href="/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93">通信原理复习总结</a></li>
        
            <li><a href="/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1">课程设计</a></li>
        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>


    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
