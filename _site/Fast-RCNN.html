<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    * Revised:        Mukosame
    -->
    <meta charset="utf-8" />
    <title>Fast R-CNN | Spyder's blog</title>
    <meta name="author" content="SpyderLord" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Everything about SpyderLord" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/.vscode" />
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">SpyderLord</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
        <div class="home-contact">
            <a href="https://github.com/SpyderLord/" target="_blank" style="margin-left:-5px;"><img src="https://github.com/favicon.ico" alt="" width="22"/></a>
           <!-- <a href="http://www.zhihu.com/people/xiang-xiao-yu-20" target="_blank" style="text-align:right"><img src="http://www.zhihu.com/favicon.ico" alt="" width="22"/></a>-->
        </div>
    </div>

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

<div id="content">
    <div class="entry">
        <h1 class="entry-title"><a href="/Fast-RCNN" title="Fast R-CNN">Fast R-CNN</a></h1>
        <p class="entry-date">2018-08-25</p>
        <h2 id="comparision-with-r-cnn-and-sppnet">Comparision with R-CNN and SPPnet</h2>
<p>　　The Region-based Convolutional Network method achieves excellent object detection accuracy by using a deep ConvNet to classify object proposals.There are several drawbacks with R-CNN:Training is complicated.When it comes to R-CNN,first of all,we have to fine-tune a ConvNet on object proposals using a log loss.Then we apply specific linear SVMs to abstract features,which act as object detectors,replacing the softmax classifier learnt by fine-tuning.In the third training stage,the bounding-box regressors are learned.What’s more,training is quite expensive in space and time.The reason why R-CNN is slow is that it performs a ConvNet forward pass for each object proposal without sharing computation.<br />
　　作者首先是以RCNN和SPPnet两种模型为例子进行分析，指出，上述的两种方式存在主要三个弊端：
- Training is a multi-stage pipeline:训练需要分成多个步骤来完成。因为自己动手敲了RCNN的网络模型，也自己训练过了一遍，确实发现了这个问题。首先我们需要大数据集来训练我们的卷及网络，然后我们小数据集对网络进行微调优化。而且在自己动手实践的过程中，发现RCNN的占用的数据空间是非常大的。输入一张图片之后，首先我们通过selective search进行region的选择，然后根据IoU的值来打上对应的标签，将数据重新保存在.npy文件中，在进行读取，是非常复杂繁琐的一个过程。在RCNN的训练过程中，第一步进行的是根据物体区域候选框去fine-tune卷积网络，这个时候使用的损失函数是softmax。第二步进行的是根据ConvNet提取出来的特征去训练一个SVM分类器。最后一步是训练一个Bounding-Box回归的学习。
- 存在的第二个问题是：训练在时间上和内存空间上的消耗是非常庞大的。
- 物体检测的过程是非常慢的：RCNN之所以非常缓慢是因为它对每一个候选区都使用卷积神经网络进行特征的提取，并没有使用计算共享的思路。<br /></p>

<p>　　Fast-RCNN模型的优点：
- 和RCNN、SPPNet相比更高的检测精度Higher detection quality(mAP).
- Training is single-stage,using a muliti-task loss.训练优化并不像之前分成了多个步骤完成，而是一个步骤就完成了。提出了multi-task loss新的评估损失函数。
- Training can update all network layers.能够更新全部的神经网络层。
- 对于特征的存储并不需要很大的内存空间。</p>

<h2 id="architecture-and-training">Architecture and training</h2>
<p>　　首先放上Fast-RCNN的网络结构：
<img src="/downloads/Fast-RCNN.png" alt="" height="290" width="420" />
- selective search在一张图片中得到大约2000个object proposals(这里称为RoI)
- 将整个图片放入一个CNN网络中得到一个总的conv feature map。每一个RoI通过ROI Pooling层可以在feature map中找到对应的固定长度的特征向量。
- 经过两个全连接层之后转变成一个RoI特征向量。该特征向量可以得到两个输出，两个输出分别是softmax分类器得到的分类结果，另一个是bounding box回归的结果。<br />
　　关于这个bounding box回归值，有一点需要额外补充的地方，也是当时在看程序的没看懂的一点，重新看了论文之后明白了这个点。原文的内容是：another layer that outputs four real-valued numbers for each of the K object classes.Each set of 4 values encodes refined bounding-box positions for one of the K classes.就是这个输出的时候到底会有多少个值，刚开始看程序的时候，看到在输出的时候使用的是一个循环在进行输出，现在结合论文来看，对于每一个分类的都会输出一组对应的4个值，这4个值用来对bounding box的位置进行重新的定位。</p>

<h3 id="the-roi-pooling-layer">The RoI pooling layer</h3>
<p>　　The RoI pooling layer uses max pooling to convert the features inside any valid region of insterest into a small feature map with a fixed spatial extent of H<em>W where H and W are layer hyper-parameters that independent of any particular RoI.<br />
　　RoI max pooling works by dividing the h</em>w RoI window into an H<em>W grid of sub-windows of approximate size h/H</em>w/W and then max-pooling the values in each sub-window into the corresponding output grid cell.<br />
　　在之前的RCNN网络中，需要将所有的region proposals都输入到CNN中，有很多计算是重复进行的。RoI pooling层的提出可以说是Fast RCNN的关键所在了。ROI pooling池化层的作用是使经过Selective search得到的region能够在整幅图像对应的feature map中对应找到自己的patch——feature vector。只需要一步就能在feature map中提取ROI对应的patch。大大提高了网络的计算效率。<br />
　　从目前的理解来看，RoI池化层和第一层的全连接层是相关联的。我们需要满足的是在全连接层的第一层输入的feature vector的size是fixed的。
### Pre-trained 
　　As the paper points out, when a pre-trained network initializes a Fast RCNN network, it undergoes three transformations.<br />
　　The last max pooling layer is replaced by a RoI pooling layer that is configured by setting H and W to be compatible with the net’s first fully connected layer.<br />
　　Second, the network’s last fully connected layer and softmax are replaced with two sibling layers described above(a fully connected layer and softmax over K+1 categories and category-specific bounding-box regressors).<br />
　　Third，the network is modified to take two data inputs: a list of images and a list of RoIs in those images. <br />
　　我们在使用大数据集与训练好了之后还需要进行进一步的微调，在训练好的网络结构上需要有三步进行调整。首先是最后一层的max pooling池化层需要改成RoI Pooling池化层，然后是最后一个全连接层和softmax被两个输出层替代，这两个层的输出一个是分类的概率p，另一个是BBX回归。网络的输入是两部分，一个是图像的输入，另一个是RoI列表。<br />
　　
## 对RoI Pooling的理解
　　感觉这篇论文中最重要的一部分就是这个RoI Pooling池化层的理解，参考CSDN上的博客，对这部分进行一个整理。依然是先给出一个链接:
<a href="https://blog.csdn.net/lanran2/article/details/60143861">https://blog.csdn.net/lanran2/article/details/60143861</a><br />
　　RoI Pooling也是池化层的一种，是针对RoIs的池化操作，特点是输入的特征图尺寸不确定，但是输出特征图的尺寸确定。这里有一点概念我们需要重点理解一下的，就是这里的输入倒是对应的是什么。<br />
　　我们通过selective search找到对应的候选框，在Fast RCNN中，RoI指的是selective search完成之后在特征图上的映射，是一个feature vector。这个映射的思路是非常重要的，因为它减少了之前RCNN中的将各个region proposals分别输入然后再去extract features的操作，很大程度上减少了计算和存储成本的开销，提高了运算的速度。<br />
　　因为之前看过Faster RCNN了，正好在这里也做一个对比。在Faster RCNN中，一个非常大的改进就是，候选框的产生不是通过Selective Search产生的，而是通过RPN产生的，然后再将各个“候选框”映射到特征图上，得到RoIs。<br />
　　给出一个更加清晰的Fast RCNN的流程图来帮助理解。
<img src="/downloads/Fast RCNN流程图.png" alt="" height="165" weight="460" />
　　从流程图中，我们可以看到的是，RoI Pooling池化层对在feature map经过映射之后得到的feature vector进行池化的操作，将RoI(还是需要记住RoI的意义是候选框在feature map上面的映射，得到的是特征向量，是候选框在feature map上面的位置，所以这里有一个问题就是，是不是在RoI之前是不经过池化曾做下采样处理的？还是需要再结合代码来进一步理解了)调整到固定的尺寸。经过RoI Pooling之后的特征向量经过全连接网络之后得到分类和回归两个输出。<br />
　　具体说一下映射的过程是如何实现的：映射的规则比较简单，将各个坐标除以输入图片与feature map的大小的比值，得到了feature map的box坐标之后，使用Pooling得到输出。在pooling的过程中，我们需要计算pooling之后的结果对应到feature map上所占的范围，然后在那个范围上进行max pooling.</p>

    </div>

    <div class="sidenav">
        <h2>Blog</h2>
        <ul class="artical-list">
        
            <li><a href="/FLaME%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3">FlaME论文阅读理解</a></li>
        
            <li><a href="/%E4%B8%89%E7%BB%B4%E5%88%9A%E4%BD%93%E7%9A%84%E8%BF%90%E5%8A%A8">刚体运动，视觉SLAM的观测方程</a></li>
        
            <li><a href="/%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E7%9A%84%E7%A8%8B%E5%BA%8F">加载预训练好的模型进行预测</a></li>
        
            <li><a href="/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A4%84%E7%90%86%E7%AE%97%E6%B3%95">SSD中的一些重要的算法</a></li>
        
            <li><a href="/SSD">SSD-MobileNet</a></li>
        
            <li><a href="/SVS%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86">SVS算法整理</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0(%E4%B8%89)">DeepLearning复习(三)</a></li>
        
            <li><a href="/Jetson_TX2%E5%BC%80%E5%8F%91">Jetson_TX2开发</a></li>
        
            <li><a href="/C++(%E4%B8%80)">C++复习（一）</a></li>
        
            <li><a href="/%E5%9C%A8linux%E4%B8%8A%E7%BC%96%E5%86%99%E4%B8%80%E4%B8%AAC++%E7%9A%84%E7%A8%8B%E5%BA%8F">在linux上使用Vim编写一个C/C++程序</a></li>
        
            <li><a href="/Ubuntu16.04%E4%B8%8B%E5%AE%89%E8%A3%85cuda-cudnn">ubuntu16.04安装显卡驱动及cuda</a></li>
        
            <li><a href="/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%9A%84%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1">研究生的数学建模</a></li>
        
            <li><a href="/Faster_RCNN">Faster RCNN</a></li>
        
            <li><a href="/Fast-RCNN">Fast R-CNN</a></li>
        
            <li><a href="/R-CNN">R-CNN学习笔记</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0%E4%BA%94">DeepLearning复习(五)</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0%E5%9B%9B">DeepLearning(四)</a></li>
        
            <li><a href="/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%A4%8D%E4%B9%A0">Deeplearning复习(三)</a></li>
        
            <li><a href="/%E4%B8%80%E6%AE%B5%E5%A5%94%E6%B3%A2%E4%B9%8B%E5%90%8E">一段奔波结束</a></li>
        
            <li><a href="/%E9%99%88%E8%80%81%E5%B8%88%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93">陈老师的论文简述</a></li>
        
            <li><a href="/Deeplearning%E5%A4%8D%E4%B9%A0-%E4%BA%8C">DeepLearning复习(二)</a></li>
        
            <li><a href="/%E5%8F%88%E6%98%AF%E4%B8%80%E7%AF%87%E5%85%B3%E4%BA%8E%E4%BF%9D%E7%A0%94%E7%9A%84%E9%9A%8F%E6%84%9F">又是保送过程中的一点随感</a></li>
        
            <li><a href="/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">大数据和机器学习学习笔记</a></li>
        
            <li><a href="/%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E7%AB%AF%E5%8D%88%E5%87%BA%E8%A1%8C">一个人的端午出游</a></li>
        
            <li><a href="/%E8%BF%98%E6%98%AF%E5%8C%97%E4%BA%AC">还是北京</a></li>
        
            <li><a href="/FaceNet%E5%AD%A6%E4%B9%A0">FaceNet学习</a></li>
        
            <li><a href="/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83">分类和回归之间的比较</a></li>
        
            <li><a href="/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0">神经网络的复习</a></li>
        
            <li><a href="/DeepLearning%E5%A4%8D%E4%B9%A0-%E4%B8%80">DeepLearning复习（一）</a></li>
        
            <li><a href="/BinarySearchTree">Binary Search Tree</a></li>
        
            <li><a href="/%E5%B0%86%E6%9D%A5%E7%9A%84%E4%BD%A0%E4%B8%80%E5%AE%9A%E4%BC%9A%E6%84%9F%E8%B0%A2%E7%8E%B0%E5%9C%A8%E5%8A%AA%E5%8A%9B%E7%9A%84%E8%87%AA%E5%B7%B1">将来的你一定会感谢现在努力的自己</a></li>
        
            <li><a href="/PSPNet%E7%9A%84%E5%AD%A6%E4%B9%A0">PSP网络的学习</a></li>
        
            <li><a href="/ResNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0">ResNet网络的学习</a></li>
        
            <li><a href="/MultiNet%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A1%A5%E5%85%85">MultiNet网络学习的补充</a></li>
        
            <li><a href="/Optimization">Optimization</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E6%89%A7%E8%A1%8C%E5%8A%9B">关于执行力</a></li>
        
            <li><a href="/FCN_Net%E7%BB%93%E6%9E%84%E7%9A%84%E4%B8%80%E7%82%B9%E8%A1%A5%E5%85%85">FCN_Net的补充</a></li>
        
            <li><a href="/FCN">FCN_Net</a></li>
        
            <li><a href="/%E6%B8%85%E6%98%8E%E5%9C%A8%E5%8C%97%E4%BA%AC">清明在北京</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%86%99%E8%87%AA%E8%8D%90%E4%BF%A1">关于写保研自荐信</a></li>
        
            <li><a href="/overfit">Overfitting</a></li>
        
            <li><a href="/ordinary-vs-cnn">普通神经网络和卷积神经网络之间比较</a></li>
        
            <li><a href="/multinet">MultiNet学习</a></li>
        
            <li><a href="/first">第一篇博文</a></li>
        
            <li><a href="/end-to-end">end-to-end</a></li>
        
            <li><a href="/WhyDeeplearning">WhyDeepLearning</a></li>
        
            <li><a href="/DataProblem">MiniDataSet</a></li>
        
        </ul>

        <h2>Dump</h2>
        <ul class="artical-list">
        
            <li><a href="/%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E9%87%8D%E5%91%BD%E5%90%8D">对文件进行重命名</a></li>
        
            <li><a href="/opencv%E5%A4%84%E7%90%86%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E8%84%9A%E6%9C%AC">opencv的一个小小脚本</a></li>
        
            <li><a href="/%E4%B8%80%E4%B8%AAidea">目标检测和深度估计的结合</a></li>
        
            <li><a href="/object_detection_api">使用tensorflow的API直接进行训练</a></li>
        
            <li><a href="/tensorboard%E5%8F%AF%E8%A7%86%E5%8C%96">TensorBoard可视化查看模型的graph</a></li>
        
            <li><a href="/scope">arg_scope</a></li>
        
            <li><a href="/tensorflow%E7%9A%84session">tensorflow的session</a></li>
        
            <li><a href="/protobuf">protobuf</a></li>
        
            <li><a href="/stringstream">stringstream</a></li>
        
            <li><a href="/C++%E4%B8%AD%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%93%8D%E4%BD%9C%E7%AC%A6">C++中的几个操作符</a></li>
        
            <li><a href="/pip3_error">pip3更新之后出错</a></li>
        
            <li><a href="/%E7%94%A8AD%E7%94%BBPCB%E6%9D%BF">使用AD制作PCB板</a></li>
        
            <li><a href="/cuda%E5%92%8Ccudnn">什么是cuda和cuDNN</a></li>
        
            <li><a href="/%E9%87%8D%E6%96%B0%E5%AE%89%E8%A3%85ubuntu16.04.05">ubuntu16.04.5的安装</a></li>
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E7%95%8C%E8%AF%BB%E5%8F%96%E5%8F%82%E6%95%B0">python解析命令行参数</a></li>
        
            <li><a href="/anaconda%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85">anaconda安装第三方包</a></li>
        
            <li><a href="/%E5%8D%B7%E7%A7%AF%E5%92%8C%E6%BB%A4%E6%B3%A2%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB">卷积和滤波之间的区别</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E9%97%AE%E9%A2%98">参数初始化的问题</a></li>
        
            <li><a href="/%E5%8F%82%E6%95%B0%E5%92%8C%E8%B6%85%E5%8F%82%E6%95%B0%E7%9A%84%E9%97%AE%E9%A2%98">参数和超参数的问题</a></li>
        
            <li><a href="/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94">杂记随笔</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E8%B4%AB%E5%AF%8C%E5%B7%AE%E8%B7%9D">关于贫富差距的感想</a></li>
        
            <li><a href="/%E4%BE%9D%E7%84%B6%E5%9B%9E%E5%BD%92%E5%92%8C%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E5%B7%AE%E5%88%AB%E7%9A%84%E9%97%AE%E9%A2%98">依然是SVM和线性回归之间的对比问题</a></li>
        
            <li><a href="/%E8%AE%AD%E7%BB%83%E9%9B%86%E9%AA%8C%E8%AF%81%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86%E7%9A%84%E4%BD%9C%E7%94%A8">训练集验证集和测试集的作用</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%89">C语言复习三</a></li>
        
            <li><a href="/%E5%85%B3%E4%BA%8E%E5%AF%BC%E5%85%A5%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98">关于导入头文件的问题</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%BA%8C">C语言复习二</a></li>
        
            <li><a href="/C%E8%AF%AD%E8%A8%80%E5%A4%8D%E4%B9%A0%E4%B8%80">C语言复习一</a></li>
        
            <li><a href="/%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8A%A0%E8%BD%BD">加载预训练好的模型时遇到的问题</a></li>
        
            <li><a href="/python%E4%BB%8E%E5%A4%96%E9%83%A8%E4%BC%A0%E5%85%A5%E5%8F%82%E6%95%B0">Python从外部传入参数</a></li>
        
            <li><a href="/%E5%A6%82%E4%BD%95%E4%BF%9D%E5%AD%98%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B">如何保存一个训练好的模型或是参数</a></li>
        
            <li><a href="/CV%E6%8C%91%E6%88%98%E8%B5%9B">CV中非常重要的挑战赛</a></li>
        
            <li><a href="/%E5%9B%BE%E8%AE%BA%E7%AE%97%E6%B3%95">图论算法</a></li>
        
            <li><a href="/%E8%BF%91%E4%B8%A4%E5%A4%A9%E5%AF%B9%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E7%82%B9%E5%B0%8F%E6%84%9F%E6%83%B3">近两天对深度学习的一点感想</a></li>
        
            <li><a href="/benchmark">几个概念的理解</a></li>
        
            <li><a href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%86">深度学习语义分割中的度量标准</a></li>
        
            <li><a href="/logits">Logits</a></li>
        
            <li><a href="/iteration%E5%92%8Cepoch">iteration和epoch比较</a></li>
        
            <li><a href="/Batch_Normalization">Batch_Normalization</a></li>
        
            <li><a href="/Memory_arrangement">linux动态内存管理</a></li>
        
            <li><a href="/ground_truth">ground truth</a></li>
        
            <li><a href="/VGG16">CNN_Architecture</a></li>
        
        </ul>

        <h2>Project</h2>
        <ul class="artical-list">
        
            <li><a href="/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86%E6%80%BB%E7%BB%93">通信原理复习总结</a></li>
        
            <li><a href="/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1">课程设计</a></li>
        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>


    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
