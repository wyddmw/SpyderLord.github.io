---
layout: post
category: dump
title: 加载预训练好的模型时遇到的问题
description: .pb .ckpt .meta
---

　　因为使用的数据集是带有很大程度上遮挡的人脸数据集，为了提高网络模型的精度，决定重新训练DeepNet，但是在加载数据集的时候，发现一个问题，就是我们下载的预训练的模型是没有.ckpt文件的。在上一篇的dump中，简单写了关于tf.train.saver()的一个介绍，但是对函数运行之后生成的文件有各自的作用并没有仔细说明，在这里进行一下补充。
- checkpoint：这个文件中存放的是预训练好的模型地址。模型文件列表checkpoint。里面记录了保存最新的checkpoint文件以及其他checkpoint文件列表。在inference的时候，可以通过修改这个文件，指定使用哪个model。
- model.meta文件：这个文件存放的是你预训练好的模型的graph。解析这个文件可以得到当初保存模型时所存储的变量的名称和形状。也就是计算图结构。每个变量的取值保存在checkpoint中。
- model.ckpt文件：这个文件是一个二进制的文件，保存了所有的weights、biases、gradients等变量。
- model.ckpt.index文件和model.ckpt.data-00000-of-00001之类的文件。这两个文件在重载checkpoint文件读取其中的参数取值的时候，缺一不可。<br>
　　说到最后一个文件，saver()函数在版本1的时候输出的变量是三个，checkpoint、model.ckpt、model.ckpt.meta文件。在版本三的时候，会生成四个文件：checkpoint、model.ckpt-2317.data-00000-of-00001、model.ckpt-2317.index、model.meta文件这四个文件。<br>
　　在加载一个预训练好的模型的时候，通常使用的函数是tf.restore()函数。但是这个函数传入的参数是.ckpt文件。我们在下载了facenet提供的预训练好的模型之后，发现文件中并没有checkpoint文件，取而代之的是一个.pb文件。将参数设定好之后发现程序并不能正常运行，一直报错要不就是找不到对应的模型文件，要不就是文件的格式不正确。在网上还专门搜索了.pb文件，和旁边的研究生也讨论了这个问题，.pb主要是保存了一个计算图文件。我们是不能通过.pb文件去进行模型的加载的。下面给出解决问题的代码:

```python 
def load_model(model, input_map=None):
    # Check if the model is a model directory (containing a metagraph and a checkpoint file)
    #  or if it is a protobuf file with a frozen graph
    model_exp = os.path.expanduser(model)
    if (os.path.isfile(model_exp)):
        print('Model filename: %s' % model_exp)
        with gfile.FastGFile(model_exp,'rb') as f:
            graph_def = tf.GraphDef()
            graph_def.ParseFromString(f.read())
            tf.import_graph_def(graph_def, input_map=input_map, name='')
    else:
        print('Model directory: %s' % model_exp)
        meta_file, ckpt_file = get_model_filenames(model_exp)
        
        print('Metagraph file: %s' % meta_file)
        print('Checkpoint file: %s' % ckpt_file)
      
        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)
        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))

def get_model_filenames(model_dir):
    files = os.listdir(model_dir)
    meta_files = [s for s in files if s.endswith('.meta')]
    if len(meta_files)==0:
        raise ValueError('No meta file found in the model directory (%s)' % model_dir)
    elif len(meta_files)>1:
        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)
    meta_file = meta_files[0]
    ckpt = tf.train.get_checkpoint_state(model_dir)
    if ckpt and ckpt.model_checkpoint_path:
        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)
        return meta_file, ckpt_file

    meta_files = [s for s in files if '.ckpt' in s]
    max_step = -1
    for f in files:
        step_str = re.match(r'(^model-[\w\- ]+.ckpt-(\d+))', f)
        if step_str is not None and len(step_str.groups())>=2:
            step = int(step_str.groups()[1])
            if step > max_step:
                max_step = step
                ckpt_file = step_str.groups()[0]
    return meta_file, ckpt_file
```
　　在这个函数中，根据传入参数的不同执行不同的分支程序。如果我们将.pb文件传入，执行的就是第一个if语句，去生成一个图变量。如果我们传入的是一个文件夹，对应的就是执行第二个if分支，去生成一个checkpoint文件和一个meta文件。然后进行一次restore的操作。

## 2018-11-12 分割线2018-11-12
　　最近自己仿照着一个demo完成了一个inference程序的编写。来简单总结一下程序中使用到的tf编程的一些tips：<br>

```python
import numpy as np
import os
import six.moves.urllib as urllib
import tarfile 
import tensorflow as tf
import cv2
import yaml
import argparse

from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util
from stuff.helper import FPS2,WebcamVideoStream

#定义获取外界变量的函数
def get_arguments():
  parser=argparse.ArgumentParser()
  parser.add_argument("--model_name",type=str,default='ssd_mobilenet_v11_coco',help='name of the pretraind model for inference')
  parser.add_argument("--model_path",type=str,default='models/ssd_mobilenet_v11_coco/frozen_inference_graph.pb',help='path to load the model')
  parser.add_argument("--label_path",type=str,default='object_detection/data/mscoco_label_map.pbtxt',help='path to load labels')
  parser.add_argument("--process_mode",type=str, default='image',help="option for image processing or video processing,either image or video")
  parser.add_argument("--num_classes",type=int,default=90)
  parser.add_argument("--visualize",type=bool,default=True)
  parser.add_argument("--max_frames",type=int,default=500)
  parser.add_argument("--width",type=int,default=300)
  parser.add_argument("--height",type=int,default=300)
  parser.add_argument("--fps_interval",type=int,default=15)
  parser.add_argument("--allow_memory_growth",type=bool,default=True)
  parser.add_argument("--det_interval",type=int,default=75)
  parser.add_argument("--det_th",type=float,default=0.5)
  return parser.parse_args()

def load_frozenmodel():
  # load params from console
  args=get_arguments()
  print('load frozenmodel\n')
  # load a frozen TensorFlow model into memory
  detection_graph=tf.Graph()                #创建一个图的对象
  with detection_graph.as_default():        #将创建的图作为默认的图
    od_graph_def=tf.GraphDef()              #新建一个GraphDef文件，用于临时载入模型中的图
    with tf.gfile.GFile(args.model_path,'rb') as fid:   #类似python中的open函数，返回一个句柄
      serialized_graph=fid.read()           
      od_graph_def.ParseFromString(serialized_graph)    #od_graph_def加载模型中的图
      tf.import_graph_def(od_graph_def,name='')         #在空白的图中加载GraphDef中的图
  #load label map
  label_map=label_map_util.load_labelmap(args.label_path)
  categories=label_map_util.convert_label_map_to_categories(label_map,
max_num_classes=args.num_classes,use_display_name=True)
  category_index=label_map_util.create_category_index(categories)
  #print(category_index.items())
  return detection_graph,category_index

def detection(detection_graph,category_index):
  # Session Config: Limit GPU Memory Usage
  print('processing detection')
  args=get_arguments()
  config=tf.ConfigProto()		
  config.gpu_options.allow_growth=args.allow_memory_growth
  print(type(args.allow_memory_growth))
  print(args.allow_memory_growth)
  cur_frames=0
  # detection part
  with detection_graph.as_default():
    with tf.Session(graph=detection_graph,config=config) as sess:
      #Definite input and output Tensors for 
      #在图中获取张量需要使用graph.get_tensor_by_name加张量名 这里的张量可以直接使用sess.run()的方法进行求值了
      #另外一点需要注意的是：获取张量的时候，比如conv1:0表示的是张量的名称，表示节点的第一个输出张量，而conv1表示的是节点名称。
      image_tensor=detection_graph.get_tensor_by_name('image_tensor:0')
      #Each box represents a part of the image where a particular object was detected
      detection_boxes=detection_graph.get_tensor_by_name('detection_boxes:0')
      #Each score represent how level of confidence for each of the objects
      #Score is shown on the result image,together with the class label
      detection_scores=detection_graph.get_tensor_by_name('detection_scores:0')
      detection_classes=detection_graph.get_tensor_by_name('detection_classes:0')
      num_detections=detection_graph.get_tensor_by_name('num_detections:0')
      #video or image process
      if (args.process_mode=='image'):
        print("image process")
        for i in range(173):
          print("processing image_%d\n"%(i+1))
          img_path='./0m/'+'23.png'    
          img=cv2.imread(img_path)
          print("1")
	#img=cv2.resize(img,(args.width,args.height))
          image_np_expanded=np.expand_dims(img,axis=0)
          (boxes,scores,classes,num)=sess.run  ([detection_boxes,detection_scores,detection_classes,num_detections],feed_dict={image_tensor:image_np_expanded}) 
          print('2')              
        # visualize
          vis_util.visualize_boxes_and_labels_on_image_array(img,np.squeeze(boxes),np.squeeze(classes).astype(np.int32),np.squeeze(scores),category_index,use_normalized_coordinates=True,line_thickness=8)
          print('3')
          #cv2.imshow('object_detection',img)
#	  cv2.waitKey()
          cv2.imwrite(str(i+1)+'.png',img)
	  print("detection_finished")
        else:
          print("process mode wrong")  
              
def main():
  detection_graph,category_index=load_frozenmodel()
  detection(detection_graph,category_index)

if __name__=='__main__' :
  main() 

```