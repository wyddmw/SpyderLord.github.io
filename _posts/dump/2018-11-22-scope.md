---
layout: post
category: dump
title: scope和variable
description: tf中经常会见到的各种scope，查资料记录一下
---

## Variable

　　tensorflow中图变量的定义：

```python
#定义的基本等价
v=tf.get_variable('v',shape=[1],initializer.constant_initializer(1.0))	#变量的名称是不可选的
#可以根据变量名去创建或是获取变量
v=tf.Variable(tf.constant(1.0,shape=[1]),name='v')						#变量的名称是可选的参数，但是图变量的初始值是必须的。
#所以两个函数都能够进行变量的初始化
```



## Scope

### slim.arg_scope()

　　在之前的某一篇的dump中应该是记录过这个函数的，但是找不到记在什么地方了，重新整理一下这个内容，slim.arg_scope的功能是定义函数的默认输入，这样在多次使用这个函数的时候，就不需要重复写这个参数了，可以使用列表的形式来同时定义多个函数的默认参数，当然前提是这些函数都要有这些参数。举栗子：

```python
with slim.arg_scope([slim.conv2d,slim.fully_connected],trainable=True,activation_fn=tf.nn.relu,weights_initializier=tf.truncated_normal_initializer(stddev=0.01),weights_regularier=slim.l2_regularizer(0.0001)):
    #定义了slim.conv2d和slim.fully_connected函数的默认参数，在接下来这段作用域内，使用这些函数的时候，默认的参数就是上面的部分
    #slim.arg_scope是可以嵌套的
    with slim.arg_scope([slim.con2d],kernel_size=[3,3],padding='SAME',normalizer_fn=slim.batch_norm):
        net=slim.conv2d(net,64,scope='conv1')
        net=slim.conv2d(net,128,scope='conv2')
        net=slim.conv2d(net,256,[5,5],scope='conv3')
```

### tf.Variable_scope()

　　这个命名空间也是这两天经常见到的了，做一个整理。<br>

　　tensorflow提供variable_scope的这种机制来实现变量的共享。这个机制主要涉及两个函数：

```python
tf.get_variable(<name>,<shape>,<initializer>)		#创建或返回给定名称的变量
tf.variable_scope(<scope_name>)						#管理传给get_variable()的变量名称的作用域

#在下面的代码中，通过tf.get_variable()创建了名称分别为weights和biases的两个变量
def conv_relu(input,kernel_shape,bias_shape):
  weights=tf.get_variable('weights',kernel_shape,initializer=tf.random_normal_initializer())
  	biases=tf.get_variable('biases',bias_shape,initializer=tf.constant_initializer(0.0))
    conv=tf.nn.conv2d(input,weights,strides=[1,1,1,1],padding='SAME')
    return tf.nn.relu(conv+biases)

def my_image_filter(input_image):
    #通过tf.variable_scope()指定作用域进行区分
    with tf.variable_scope('conv1'):				#这行代码指定了第一个卷积层作用域为conv1，在这个作用域下有两个变量weights和bias，对应的变量的名称是'conv1/weights','conv1/biases'
        relu1=conv_relu(input_image,[5,5,32,32],[32])                
	with tf.variable_scope('conv2'):				#对应变量的名称是'conv2/weights','conv2/biases'
        return conv_relu(relu1,[5,5,32,32],[32])
    
#对于scope来说，tf.variable_scope()用来指定变量的作用域，作为变量名的前缀，支持嵌套
with tf.variable_scope('foo'):
    with tf.variable_scope('bar'):
        v=tf.get_variable("V",[1])					#变量的名称因该是foo/bar/v       

```

　　所以写到这里对于scope的理解就会清楚一些，关于reuse这个标志位的问题，什么时候用到了什么时候再查找吧。<br>

　　所以总结下来就是，scope应该是配合着get_variable()这个函数来使用的，通过variable_scope()能够有效的管理这个作用域空间下的变量。只是在程序中看到的通常是：

```python
with tf.variable_scope('vgg'):
	net=slim.conv2d(input,kernel_size,stride,padding)	#如果去看slim。conv2d的底层实现，应该也是使用的get_variable()的方式进行变量的定义
```

