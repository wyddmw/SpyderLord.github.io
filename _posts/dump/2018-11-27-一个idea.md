---
layout: post
category: dump
title: 目标检测和深度估计的结合
description: 最近的一些小想法
---

　　因为研究生的方向如果不出意外的话会做单目深度估计方面的内容，但是最近一段时间想了这个方向，发现了一些问题：
- 单纯的实现深度估计是否有较高的实用价值，之前运行SVS的时候，出来的效果图中，一幅图像中黑压压的一片深度信息，这样的输出它有效的价值在哪里，就像日常生活中，虽然我们能得到视觉中所有物体的深度信息，但是我们需要知道视觉中的所有物体的距离信息吗，我觉得是不需要的，深度的信息是存在很大的冗余的，从计算量上来说，这对计算机来说也是增加了一些不必要的负担，如果我们只是对自己感兴趣的物体进行深度的估计的话，我觉得是没有必要计算出来整张图像的深度信息的。
- 那么问题来了，如果只是想要得到自己想要物体的深度信息，我觉得第一步就是先要在图像中找到自己想要的物体，这就是目标检测的任务。所以我想的一个问题就是，如果将深度估计和目标检测两者相互结合起来的话，输出的信息会更有价值一些。从目前已有的知识上来看这个问题，还没有想出来如何将网络设计成为end-to-end的网络结构。粗略的一个想法就是将这个任务分成两个部分来完成，分别对应任务深度估计和目标检测，但是提取特征的网络可以共享，来减少计算量。
- 和自动化所的田老师交流了，从他哪里得到的消息是使用单目摄像头做深度估计目前是非常不准确的，在无人驾驶这个领域内，使用激光雷达来定位得到距离信息然后使用摄像头进行目标检测，再将两者相融合得到目标的深度信息。
- 那么后面能不能使用激光雷达的深度信息和视觉中的信息来做融合呢？我觉得也未尝不是不可。