---
layout: post
category: dump
title: 参数初始化的问题
description: 初始化参数的时候需要注意的问题，梯度消失和梯度爆炸
---

## 参数初始化的目的是什么
　　为了让神经网络在训练的过程中学习到有用的信息，反向传播的时候参数的导数肯定是不能等于零的。参数的初始化应该满足两个条件：
- 各层激活值不会出现饱和的情况，我觉得可以理解为初始化的参数的绝对值不能过大。
- 各层激活值不能等于零，如果等于零的话，在反向传播的时候肯定对应的梯度也就等于零了。

## 梯度消失和梯度爆炸
　　我们在训练神经网络的时候，会面临的一个问题就是梯度消失或是梯度爆炸，也就是我们训练神经网络的时候，导数可能会变得非常大或是非常小，这就会加大训练的难度。权重W比单位矩阵稍稍大一点的话，深度神经网络的激活函数将会爆炸式增长，在深度神经网络中，激活函数将以指数级递增，对于导数或是梯度函数来说也是一样的，也会呈现指数级增长或是指数递减。所以对参数的初始化做好是非常重要的。

## 生成小的随机数
　　将参数初始化为小的随机数，初始化的参数服从均值为零，方差为1的标准正态分布，会乘以一个较小的系数。