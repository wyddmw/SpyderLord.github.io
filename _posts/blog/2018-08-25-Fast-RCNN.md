---
layout: post
category: blog
title: Fast R-CNN
description: 
---

## Comparision with R-CNN and SPPnet
　　The Region-based Convolutional Network method achieves excellent object detection accuracy by using a deep ConvNet to classify object proposals.There are several drawbacks with R-CNN:Training is complicated.When it comes to R-CNN,first of all,we have to fine-tune a ConvNet on object proposals using a log loss.Then we apply specific linear SVMs to abstract features,which act as object detectors,replacing the softmax classifier learnt by fine-tuning.In the third training stage,the bounding-box regressors are learned.What's more,training is quite expensive in space and time.The reason why R-CNN is slow is that it performs a ConvNet forward pass for each object proposal without sharing computation.<br>
　　作者首先是以RCNN和SPPnet两种模型为例子进行分析，指出，上述的两种方式存在主要三个弊端：
- Training is a multi-stage pipeline:训练需要分成多个步骤来完成。因为自己动手敲了RCNN的网络模型，也自己训练过了一遍，确实发现了这个问题。首先我们需要大数据集来训练我们的卷及网络，然后我们小数据集对网络进行微调优化。而且在自己动手实践的过程中，发现RCNN的占用的数据空间是非常大的。输入一张图片之后，首先我们通过selective search进行region的选择，然后根据IoU的值来打上对应的标签，将数据重新保存在.npy文件中，在进行读取，是非常复杂繁琐的一个过程。在RCNN的训练过程中，第一步进行的是根据物体区域候选框去fine-tune卷积网络，这个时候使用的损失函数是softmax。第二步进行的是根据ConvNet提取出来的特征去训练一个SVM分类器。最后一步是训练一个Bounding-Box回归的学习。
- 存在的第二个问题是：训练在时间上和内存空间上的消耗是非常庞大的。
- 物体检测的过程是非常慢的：RCNN之所以非常缓慢是因为它对每一个候选区都使用卷积神经网络进行特征的提取，并没有使用计算共享的思路。<br>

　　Fast-RCNN模型的优点：
- 和RCNN、SPPNet相比更高的检测精度Higher detection quality(mAP).
- Training is single-stage,using a muliti-task loss.训练优化并不像之前分成了多个步骤完成，而是一个步骤就完成了。提出了multi-task loss新的评估损失函数。
- Training can update all network layers.能够更新全部的神经网络层。
- 对于特征的存储并不需要很大的内存空间。

## Architecture and training 
　　首先放上Fast-RCNN的网络结构：
![](/downloads/Fast-RCNN.png){:height="290" width="420"}
- selective search在一张图片中得到大约2000个object proposals(这里称为RoI)
- 将整个图片放入一个CNN网络中得到一个总的conv feature map。每一个RoI通过ROI Pooling层可以在feature map中找到对应的固定长度的特征向量。
- 经过两个全连接层之后转变成一个RoI特征向量。该特征向量可以得到两个输出，两个输出分别是softmax分类器得到的分类结果，另一个是bounding box回归的结果。<br>

### The RoI pooling layer
　　The RoI pooling layer uses max pooling to convert the features inside any valid region of insterest into a small feature map with a fixed spatial extent of H*W where H and W are layer hyper-parameters that independent of any particular RoI.<br>
　　RoI max pooling works by dividing the h*w RoI window into an H*W grid of sub-windows of approximate size h/H*w/W and then max-pooling the values in each sub-window into the corresponding output grid cell.<br>
　　在之前的RCNN网络中，需要将所有的region proposals都输入到CNN中，有很多计算是重复进行的。RoI pooling层的提出可以说是Fast RCNN的关键所在了。ROI pooling池化层的作用是使经过Selective search得到的region能够在整幅图像对应的feature map中对应找到自己的patch——feature vector。只需要一步就能在feature map中提取ROI对应的patch。大大提高了网络的计算效率。<br>
　　从目前的理解来看，RoI池化层和第一层的全连接层是相关联的。我们需要满足的是在全连接层的第一层输入的feature vector的size是fixed的。
### Pre-trained 
　　As the paper points out, when a pre-trained network initializes a Fast RCNN network, it undergoes three transformations.<br>
　　The last max pooling layer is replaced by a RoI pooling layer that is configured by setting H and W to be compatible with the net's first fully connected layer.<br>
　　Second, the network's last fully connected layer and softmax are replaced with two sibling layers described above(a fully connected layer and softmax over K+1 categories and category-specific bounding-box regressors).<br>
　　Third，the network is modified to take two data inputs: a list of images and a list of RoIs in those images. <br>
　　我们在使用大数据集与训练好了之后还需要进行进一步的微调，在训练好的网络结构上需要有三步进行调整。首先是最后一层的max pooling池化层需要改成RoI Pooling池化层，然后是最后一个全连接层和softmax被两个输出层替代，这两个层的输出一个是分类的概率p，另一个是BBX回归。网络的输入是两部分，一个是图像的输入，另一个是RoI列表。<br>
　　
