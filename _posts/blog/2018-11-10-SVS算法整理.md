---
layout: post
category: blog
title: SVS算法整理
description: 先重点整理一下stereo matching部分的程序
---

　　现有的基于深度学习的单目深度估计方法，通常是将CNN网络作为一个黑盒子来使用，学习图像块到深度值的直接映射，这类方法完全依赖高级语义信息作为预测深度的依据，尽管有些方法在损失函数上引入了一些特殊的约束条件，学习这样的语义信息仍然是非常困难的。另一方面，即使这样的映射能够被成功训练出来，算法可能需要非常大量的带有深度标签值的真实数据，对数据的采集提出了很高的要求，也限制了这类技术的适用场景。整个网络将双目深度估计分解成为两个部分来完成，第一个部分是视觉合成网络——View Synthesis Network，第二个部分是双目匹配模型——Stereo Matching Network。这样的分解带来了两个显著的优势，一方面是极大减少了深度标注数据的依赖，在测试阶段，显式地引入了几何约束。<br>
　　关于这个模型的精度问题，首先是超过了Kitti上所有单目深度估计方法，并首次依赖单目深度图像数据就超过了双目匹配算法Block Matching的深度估计。<br>
　　模型的视图合成过程由视图合成网完成，输入一张左图，网络合成该图像对应的右图；而双目匹配过程由双目匹配网络完成，接收左图和合成的右图，预测出左图每一个像素的视差值。![/downloads/SVS.png](/downloads/SVS.png)

### 概念
- Disparity视差：从有一定距离的两个点上观测同一个目标所产生的方向差异。
- 双目立体视觉匹配：从双目相机所获取的左眼图像和右眼图像中恢复出逐像素点的深度。<br>

## DispNet
　　因为实际上SVS可以看做是两部分网络结构的合成，对于双目视觉匹配问题来说，