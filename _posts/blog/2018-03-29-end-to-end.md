---
layout: post
category: blog
title: end-to-end
description: 端到端的DL学习
---

## END-TO-END Network
- 在看FCN论文的时候读到了这个名词，原文中提到这个名词的句子是：Convolutional networks are powerful visual models that yield hierarchies of features.We show that convolutional networks by themselves,trained end-to-end,pixels-to-pixels,exceed the state-of-the-art in semantic segmentation.翻译过来就是卷积网络在特征分层领域是非常强大的视觉模型。我们证明了经过端到端、像素到像素训练的卷积网络超过语义分割中最先进的技术。
- 这段文字出现论文的首段，当时读的时候并没有对这个端对端有什么感觉，直到在看了实现的代码之后，在谷歌上搜索的时候偶然发现了有关于这个词条的一些解释。点进去一看，发现这完全是一个全新的领域啊。大概看了一边，也不是特别理解，对目前看到的部分进行一下简单的总结。
### 一些知乎大牛的回答：
- 经典机器学习方式是以人类的先验知识将raw data数据预处理成为feature，然后对feature进行分类。分类结果十分取决于feature的好坏。在过去的时候，我们会将大部分时间花费在设计feature上。之后人们发现，利用神经网络可以让网络自己抓取feature。随着网络的进一步加深，多层次的representation learning将识别率提升到一个新的高度。然后我们就听到了一个很多人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。 
- end-to-end的好处，通过缩减人工预处理和后续的处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。
- 在视觉领域而言，end-to-end一词多用于基于视觉的机器控制方面，具体表现是，神经元的输入为原始图片，神经网络的输出为控制指令，比如说对于自动驾驶而言，输入图片，直接输出steering angle。从视频来看效果还是不错的。end-to-end并不是什么新的东西，仅仅是直接输入raw data然后直接输出最终目标的一种思想。
- end-to-end应该翻译成为端到端，输入原始的数据，输出的是最终的结果。原来输入端输入的不是直接的原始数据，而是在原始数据中提取的特征。由于图像的像素太多，数据的维度很高，会产生维度灾难，所以原来的思路是手工提取图像的一些关键的特征，实际上这就是一个降维的过程。那么我们应该如何提取特征呢？特征提取的好坏是非常重要的。特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。然后出现了端到端网络，特征可以自己去学习，特征进一步融入到算法之中，不需要人来进行干预了。

### 接下来是自己的一些理解：
- 在看了李宏毅教授的视频之后，自己想了想，感觉end-to-end learning其实我们已经在使用了，我觉得我们现在使用的CNN、FCN等都是end-to-end的例子。还是以语音信号为例子，在多年前，人们对语音信号的分析，是先对其进行FFT、DFT等，得到一系列hand-crafted的feature，然后在对这些feature进行人为的分类。如果是加上了learning的影子，那就是在得到一系列的feature之后，加上一层hidden layer，最后输出对应的label。这样的操作其实只有一层hidden layer是在进行learning data，之前的预处理其实都是hand-crafted得到的。
- 后来人们就想，能不能直接输入语音信号，然后直接得到对应的label呢？换句话说就是我们使用很多层的hidden layers来代替之前人为的那些hand-crafted的操作，让每一层network都成为一个又一个function，所有这些function都是从数据中自动学习到的。 下面是图像识别中的一个例子
![](/downloads/shallowapproach.png)
![](/downloads/deeplearning.png)