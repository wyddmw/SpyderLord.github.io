---
layout: post
category: blog
title: FaceNet学习
description: Triplet Loss、Inception-Res-V2、GoogleNet
---

## 写在前面
　　首先是为什么要学习这个FaceNet。和研究生一起参加一个智慧城市的比赛，赛题就是带遮挡的人脸识别。和之前做的中科院的项目也算是有点联系，都是机器视觉方面的内容。在我看这个赛题还是比较有意思的，也是比较符合当前生活的场景的，每一个人的图片只有很少的几张，但是会有非常多的人需要进行识别。按照之前的思路，对应的会有非常多的种类，但是每个种类对应的图片的数量非常少，如果想让机器准确每一个人的特征，然后进行识别，这显然是有点不现实的，因为每个人的图像太少了，训练出来的模型很有可能是欠拟合的。其实在现实生活中，如果我们想要做一个识别的系统的话，我们也不可能去采集非常多的图像。如果需要对一个新的人进行识别呢？重新训练去训练一下这个网络？FaceNet的提出应该说是非常好的解决了这个问题吧。
### Triplet Loss
　　这个损失是在这个网络中提出来的，就理解为三元损失函数吧。在吴恩达的课程中，对这个三元损失函数的介绍是如下的：要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降。<br>
　　使用三元组损失函数需要我们对数据集有特殊的要求，我们需要把数据集分成如下三个部分：Anchor图片，Positive图片，和Negative图片。我们需要同时看这三张照片，首先是看Anchor图片，我们希望Anchor图片和Positive图片的距离很近，Negative和Anchor不是同一个人，我们会希望对应的距离远一些，我们将对应的图片简写成APN，如果我们想把这些写成公式的话，我们希望网络的参数或者编码能够满足下面的特性：||f(A)-f(P)||^2这个数值是非常小的，其中f(A)表示提取的Anchor图片的特征。我们希望它小于等于f(A)和f(N)之间的距离，或是说它们范数的平方。(即||f(A)-f(P)||^2<=||f(A)-f(N)||^2)，然后我们可以对这个这个式子再进行一下修改，添加一个间隔参数，有点类似于SVM损失函数。就是我们希望f(A)、f(P)之间的距离和f(A)、f(N)之间的距离差至少要比这个间隔参数要大。<br>
　　Loss(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+a,0)，其实和SVM的损失函数非常像了，就是只要能够满足这个距离的间隔就认为是理想的了。